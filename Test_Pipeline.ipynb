{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okBsK2cOLYZU"
   },
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJ92N2C1vj1g"
   },
   "outputs": [],
   "source": [
    "!pip install nemo_toolkit[all]\n",
    "!pip install pydub\n",
    "!pip install wget\n",
    "!pip install zipfile\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install pympi-ling\n",
    "!pip install librosa\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eK-l4_MMcq3"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0rwv6GTE0iI"
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence, detect_nonsilent\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import wget\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import pympi\n",
    "import zipfile\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Pipeline\n",
    "from nltk import wordpunct_tokenize\n",
    "from collections import Counter\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG-SRiBFFEoU"
   },
   "source": [
    "# Split sound to fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-r3QL43E6ag"
   },
   "outputs": [],
   "source": [
    "def get_intervals(path):\n",
    "    print('Start record processing...')\n",
    "    start = time.time()\n",
    "    aud, sr = librosa.load(path, sr=16000)\n",
    "    new_path = '/content/audio_16.wav'\n",
    "    sf.write(new_path, aud, sr)\n",
    "    sound = AudioSegment.from_wav(new_path)\n",
    "    sound = sound.set_channels(1)\n",
    "    result = detect_nonsilent(sound, min_silence_len=700, silence_thresh=sound.dBFS-14, seek_step=5)\n",
    "    final = []\n",
    "    next_was_added = False\n",
    "    for i in range(len(result)):\n",
    "        if next_was_added == False:\n",
    "            if (result[i][1]/1000-result[i][0]/1000 > 1):\n",
    "                final.append(result[i])\n",
    "            else:\n",
    "                if i != len(result):\n",
    "                    last_verif = final[-1]\n",
    "                    next_item = result[i+1]\n",
    "                else:\n",
    "                    last_verif = final[-1]\n",
    "                    next_item = [-100, -100]\n",
    "                if (result[i][0] - last_verif[1])/1000 < 1:\n",
    "                    final[-1][1] = result[i][1]\n",
    "                elif 0 < (next_item[0]-result[i][1])/1000 < 1:\n",
    "                    final.append([result[i][0], next_item[1]])\n",
    "                    next_was_added = True\n",
    "                else:\n",
    "                    if result[i][1]/1000-result[i][0]/1000 > 0.01:\n",
    "                        final.append(result[i])\n",
    "                    else:\n",
    "                        pass\n",
    "        else:\n",
    "            next_was_added = False \n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Done in ' + str(datetime.timedelta(seconds=total_time)))\n",
    "    \n",
    "    return sound, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0hZd0uKFBpn"
   },
   "outputs": [],
   "source": [
    "def split_sound(sound, chunks):\n",
    "    print('Start record chuncking...')\n",
    "    start = time.time()\n",
    "    manifest_full = []\n",
    "    current_directory = os.getcwd()\n",
    "    final_directory = os.path.join(current_directory, r'audio_segments')\n",
    "    if os.path.exists(final_directory) and os.path.isdir(final_directory):\n",
    "        shutil.rmtree(final_directory)\n",
    "    os.makedirs(final_directory)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        segment = sound[chunk[0]:chunk[1]]\n",
    "        path_segment = os.path.join(final_directory, str(i) + '.wav')\n",
    "        segment.export(path_segment, format='wav')\n",
    "        manifest_full.append({'audio_filepath': path_segment, \n",
    "                              'duration': (chunk[1]-chunk[0])/1000, \n",
    "                              'xmin': chunk[0]/1000, \n",
    "                              'xmax': chunk[1]/1000})\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Done in ' + str(datetime.timedelta(seconds=total_time)))\n",
    "    print('Folder with audio segments: ' + final_directory)\n",
    "    return manifest_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VATrs0RnFQV9"
   },
   "source": [
    "# Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6b2OJD6FTaR"
   },
   "outputs": [],
   "source": [
    "def get_transcriptions(manifest, model_type):\n",
    "    print('Start transcribing...')\n",
    "    start = time.time()\n",
    "    if model_type == 'zapdvin':\n",
    "        url = 'https://storage.yandexcloud.net/dialect-speech-recognition-and-feature-detection/finetuned_conformer.nemo?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=YCAJEUEYBLmE9j6wqGUjKoE1r%2F20230529%2Fru-central1%2Fs3%2Faws4_request&X-Amz-Date=20230529T152617Z&X-Amz-Expires=1209600&X-Amz-Signature=C45CBC6562D8880D5EFFC05A811DC9BB211938AA3CA890EC8DC690952203128F&X-Amz-SignedHeaders=host'\n",
    "        filename = wget.download(url, out='/content/conformer_zapdvin.nemo')\n",
    "    if model_type == 'opochka':\n",
    "        url = 'https://storage.yandexcloud.net/dialect-speech-recognition-and-feature-detection/finetuned_conformer_opochka.nemo?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=YCAJEUEYBLmE9j6wqGUjKoE1r%2F20230529%2Fru-central1%2Fs3%2Faws4_request&X-Amz-Date=20230529T153308Z&X-Amz-Expires=1209600&X-Amz-Signature=8F163739C6D5923A09B2A6888FD0023D0278AB7D2CF7D6590EDEBA01C7ADAF89&X-Amz-SignedHeaders=host'\n",
    "        filename = wget.download(url, out='/content/conformer_zapdvin.nemo')\n",
    "    asr_model = nemo_asr.models.EncDecRNNTBPEModel.restore_from(restore_path=filename)\n",
    "    files = [file['audio_filepath'] for file in manifest]\n",
    "    transcriptions = asr_model.transcribe(paths2audio_files=files)\n",
    "    for i, item in enumerate(manifest):\n",
    "        item['transcription'] = transcriptions[0][i]\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Done in ' + str(datetime.timedelta(seconds=total_time)))\n",
    "    return manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piV-eCepJptc"
   },
   "source": [
    "# Get TextGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJu545SQJmjS"
   },
   "outputs": [],
   "source": [
    "def prepare_textgrid(manifest):\n",
    "    print('Preparing TextGrid...')\n",
    "    start = time.time()\n",
    "    xmin = 0.0\n",
    "    xmax = manifest[-1]['xmax']\n",
    "    size = len(manifest)\n",
    "    header = 'File type = \"ooTextFile\"\\nObject class = \"TextGrid\"\\nxmin = {xmin}\\nxmax = {xmax}\\ntiers? <exists>\\nsize = 1\\nitem []:\\n'.format(xmin=xmin, xmax=xmax)\n",
    "    item_1 ='    item[1]:\\n        class = \"IntervalTier\"\\n        name = \"{name}\"\\n        xmin = {xmin}\\n        xmax = {xmax}\\n        intervals: size = {size}\\n'.format(name='text', xmin=xmin, xmax=xmax, size=size)\n",
    "    current_directory = os.getcwd()\n",
    "    final_directory = os.path.join(current_directory, r'result.TextGrid')\n",
    "    with open(final_directory, 'w', encoding='utf-8') as f:\n",
    "        f.write(header)\n",
    "        f.write(item_1)\n",
    "        i = 1\n",
    "        for item in manifest:\n",
    "            f.write('        intervals [{num}]'.format(num=i))\n",
    "            f.write('\\n')\n",
    "            f.write('            xmin = {start}'.format(start=item['xmin']))\n",
    "            f.write('\\n')\n",
    "            f.write('            xmin = {end}'.format(end=item['xmax']))\n",
    "            f.write('\\n')\n",
    "            f.write('            text = \"{transcription}\"'.format(transcription=item['transcription']))\n",
    "            f.write('\\n')\n",
    "        i += 1\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Done in ' + str(datetime.timedelta(seconds=total_time)))\n",
    "    print('Location of TextGrid: ' + final_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-r7KNvdJycI"
   },
   "source": [
    "# Get dialect features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x18OyG8oMjX7"
   },
   "outputs": [],
   "source": [
    "class MyPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        preprocess_kwargs = {}\n",
    "        if \"tokenizer\" in kwargs:\n",
    "            preprocess_kwargs[\"tokenizer\"] = kwargs[\"tokenizer\"]\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        self.text_splt = wordpunct_tokenize(text.lower())\n",
    "        self.tokenized = self.tokenizer(self.text_splt, is_split_into_words=True, return_tensors='pt')\n",
    "        return self.tokenized\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        model_inputs['input_ids'] = model_inputs['input_ids'].to('cuda')\n",
    "        model_inputs['attention_mask'] = model_inputs['attention_mask'].to('cuda')\n",
    "        return self.model(**model_inputs)\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(list(self.tokenized[\"input_ids\"][0]))\n",
    "        predicted_label_id = torch.argmax(model_outputs.logits, axis=-1).numpy()\n",
    "        id2label = {0: \"O\", 1: \"B-PHON\", 2: \"B-MORPH\", 3: \"I-MORPH\", \n",
    "                    4: \"B-LEX\", 5: \"I-LEX\", 6: \"B-SYNT\", 7: \"I-SYNT\"}\n",
    "        labels = [id2label[i] for i in predicted_label_id[0]]\n",
    "        res = {'tokens': tokens, 'labels': labels}\n",
    "        result_text = ''\n",
    "        result_labels = ''\n",
    "        for i in range(len(res['tokens'])):\n",
    "            if res['tokens'][i] != '<s>' and res['tokens'][i] != '</s>':\n",
    "                if res['tokens'][i].startswith('▁'):\n",
    "                    res['labels'][i] = '▁' + res['labels'][i]\n",
    "                if i > 1:\n",
    "                    x = res['tokens'][i].replace('▁', ' ')\n",
    "                    y = res['labels'][i].replace('▁', ' ')\n",
    "                else:\n",
    "                    x = res['tokens'][i].replace('▁', '')\n",
    "                    y = res['labels'][i].replace('▁', '')\n",
    "                result_text += x\n",
    "                result_labels = result_labels + '|' + y\n",
    "        result_labels_splt = result_labels.split(' ')\n",
    "        final_labels = []\n",
    "        if result_labels_splt == ['']:\n",
    "            return {0: {0: None}}\n",
    "        else:\n",
    "          for l in result_labels_splt:\n",
    "              cnt = Counter()\n",
    "              if l[0] == '|' and l[-1] == '|':\n",
    "                  l = l[1:-1]\n",
    "              elif l[0] != '|' and l[-1] == '|':\n",
    "                  l = l[0:-1]\n",
    "              elif l[0] == '|' and l[-1] != '|':\n",
    "                  l = l[1:]\n",
    "              l_splt = l.split('|')\n",
    "              if len(l_splt) == 1:\n",
    "                  res_lab = l_splt[0]\n",
    "                  final_labels.append(res_lab)\n",
    "              if len(l_splt) > 1:\n",
    "                  cnt = Counter(l_splt)\n",
    "                  if len(dict(cnt)) == 1:\n",
    "                      res_lab = l_splt[0]\n",
    "                      final_labels.append(res_lab)\n",
    "                  else:\n",
    "                      c = dict(cnt)\n",
    "                      c.pop('O', None)\n",
    "                      res_lab = max(c, key=c.get)\n",
    "                      final_labels.append(res_lab)\n",
    "\n",
    "        txt_splt = result_text.split(' ')\n",
    "        dict_with_labels = {}\n",
    "        for i in range(len(txt_splt)):\n",
    "            dict_with_labels[i] = {txt_splt[i]: final_labels[i]}\n",
    "\n",
    "        return dict_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNQZq6RtJsob"
   },
   "outputs": [],
   "source": [
    "def get_features(manifest, model_type):\n",
    "    print('Finding features...')\n",
    "    start = time.time()\n",
    "    if model_type == 'zapdvin':\n",
    "        url = 'https://storage.yandexcloud.net/dialect-speech-recognition-and-feature-detection/xlm_roberta_base_dial.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=YCAJEUEYBLmE9j6wqGUjKoE1r%2F20230529%2Fru-central1%2Fs3%2Faws4_request&X-Amz-Date=20230529T154001Z&X-Amz-Expires=1209600&X-Amz-Signature=5AEB7322B6A853EFB3873968A52FFF7F842D35B63466AFFB5812FC5738B80812&X-Amz-SignedHeaders=host'\n",
    "        filename = wget.download(url, out='/content/xlm_roberta.zip')\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('/content/xlm_roberta')\n",
    "    if model_type == 'opochka':\n",
    "        url = 'https://storage.yandexcloud.net/dialect-speech-recognition-and-feature-detection/xlm_roberta_base_dial_V1_opochka.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=YCAJEUEYBLmE9j6wqGUjKoE1r%2F20230529%2Fru-central1%2Fs3%2Faws4_request&X-Amz-Date=20230529T154207Z&X-Amz-Expires=1209600&X-Amz-Signature=764989EFA172BC6F103823BCAB4EC58F135C12B417EDA7357BF46B00F0D34911&X-Amz-SignedHeaders=host'\n",
    "        filename = wget.download(url, out='/content/xlm_roberta.zip')\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('/content/xlm_roberta')\n",
    "    tokenizer = AutoTokenizer.from_pretrained('/content/xlm_roberta/xlm_roberta_base_dial/checkpoint-3000', local_files_only=True)\n",
    "    model = AutoModelForTokenClassification.from_pretrained('/content/xlm_roberta/xlm_roberta_base_dial/checkpoint-3000', local_files_only=True)\n",
    "    pipeline = MyPipeline(model=model.to('cuda'), tokenizer=tokenizer)\n",
    "    labels = []\n",
    "    for sentence in list(manifest):\n",
    "        res = pipeline(sentence['transcription'])\n",
    "        labels_sent = []\n",
    "        for key, value in res.items():\n",
    "            for key2, value2 in value.items():\n",
    "                labels_sent.append(value2)\n",
    "        labels.append(labels_sent)\n",
    "    for i, item in enumerate(manifest):\n",
    "        tokens = wordpunct_tokenize(item['transcription'].lower())\n",
    "        item['tokens'] = tokens\n",
    "        item['features'] = labels[i]\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Done in ' + str(datetime.timedelta(seconds=total_time)))\n",
    "    return manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt38yzRNQ7c2"
   },
   "source": [
    "# Write transcriptions, tokens and features to eaf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzFxNG3PQ0gM"
   },
   "outputs": [],
   "source": [
    "def prepare_elan(manifest, path):\n",
    "    print('Preparing EAF...')\n",
    "    start = time.time()\n",
    "    elan = pympi.Elan.Eaf(author='user')\n",
    "    elan.add_linked_file(path)\n",
    "    elan.remove_tiers(['default'])\n",
    "    elan.add_tier('annotation', ling='default-lt', parent=None)\n",
    "    elan.add_tier('tokens', ling='default-lt', parent='annotation')\n",
    "    elan.add_tier('features', ling='default-lt', parent='tokens')\n",
    "\n",
    "    for item in manifest:\n",
    "        if len(item['transcription']) > 0:\n",
    "            elan.add_annotation(id_tier='annotation', \n",
    "                                start=int(item['xmin'] * 1000), \n",
    "                                end=int(item['xmax'] * 1000), \n",
    "                                value=item['transcription'])\n",
    "            word_time = item['duration'] * 1000 / len(item['tokens'])\n",
    "            start_time_word_tier = item['xmin'] * 1000\n",
    "            for token in item['tokens']:\n",
    "                end_time_word_tier = start_time_word_tier + word_time\n",
    "                elan.add_annotation(id_tier='tokens', \n",
    "                                start=int(start_time_word_tier), \n",
    "                                end=int(end_time_word_tier), \n",
    "                                value=token)\n",
    "                start_time_word_tier = end_time_word_tier\n",
    "            start_time_word_tier = item['xmin'] * 1000\n",
    "            for token in item['features']:\n",
    "                end_time_word_tier = start_time_word_tier + word_time\n",
    "                elan.add_annotation(id_tier='features', \n",
    "                                start=int(start_time_word_tier), \n",
    "                                end=int(end_time_word_tier), \n",
    "                                value=token)\n",
    "                start_time_word_tier = end_time_word_tier\n",
    "\n",
    "    current_directory = os.getcwd()\n",
    "    final_directory = os.path.join(current_directory, r'result.eaf')\n",
    "    elan.to_file(file_path=final_directory)\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Done in ' + str(datetime.timedelta(seconds=total_time)))\n",
    "    print('Location of TextGrid: ' + final_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwec81WtWhUd"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "undA50_O6hdc"
   },
   "source": [
    "To test on a new audio file, you need to upload it and replace the link in the url variable. As an example, a record of 2022 from an expedition to the Zapadnodvinsky district of the Tver region is presented.\n",
    "\n",
    "To change the model type, you need to change the model_type variables in the cell below. \n",
    "\n",
    "'zapdvin' - for data of the Zapadnodvinsky district, Tver region\n",
    "\n",
    "'opochka' - for data of the Opochetsky district, Pskov region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAQwk_XfRJMf"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = 'https://storage.yandexcloud.net/dialect-speech-recognition-and-feature-detection/20220710mga1932.wav?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=YCAJEUEYBLmE9j6wqGUjKoE1r%2F20230529%2Fru-central1%2Fs3%2Faws4_request&X-Amz-Date=20230529T162054Z&X-Amz-Expires=1209600&X-Amz-Signature=84C359415EBD33413690751188EDE437DFC5624FBEEB0F0A86B55A921F5BFF42&X-Amz-SignedHeaders=host'\n",
    "    path = wget.download(url, out='/content/test.wav')\n",
    "    sound, chunks = get_intervals(path)\n",
    "    manifest = split_sound(sound, chunks)\n",
    "    manifest = get_transcriptions(manifest, model_type='zapdvin')\n",
    "    torch.cuda.empty_cache()\n",
    "    manifest = get_features(manifest, model_type='zapdvin')\n",
    "    prepare_textgrid(manifest)\n",
    "    prepare_elan(manifest, path)\n",
    "\n",
    "    # code below only for Google Chrome, for downloading in other browsers, \n",
    "    # you must select the \"folder\" icon in the left panel and download the file\n",
    "\n",
    "    files.download('/content/result.eaf') \n",
    "    files.download('/content/result.TextGrid') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8939X9tRNMm"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
