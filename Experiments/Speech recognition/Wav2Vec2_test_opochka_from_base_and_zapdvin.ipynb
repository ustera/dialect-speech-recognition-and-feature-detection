{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a95e75",
   "metadata": {},
   "source": [
    "# Import all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f189cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa\n",
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install jiwer\n",
    "!pip install scikit-learn\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe3df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from jiwer import wer, cer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd732c",
   "metadata": {},
   "source": [
    "# Define the model that was trained on dialect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa1746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"bond005/wav2vec2-large-ru-golos-with-lm\"\n",
    "model = Wav2Vec2ForCTC.from_pretrained('/content/wav2vec2-large-ru-golos-with-lm-dialect-full/checkpoint-10410/', local_files_only=True)\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92f606",
   "metadata": {},
   "source": [
    "# Processing source files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9cdd7",
   "metadata": {},
   "source": [
    "Get all files, define new sort function to sort as \\[1, 2, 3 ... 100\\], because built-in function sorts strings as \\[1, 100, 101 ...\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faaf887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df8d5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_files(directory, file_with_text, inf):\n",
    "    with open(file_with_text, encoding='utf-16') as f:\n",
    "        text = f.readlines()\n",
    "    files = os.listdir(directory)\n",
    "    files_full = []\n",
    "    for filename in files:\n",
    "        if '.DS_Store' not in filename:\n",
    "            f = os.path.join(directory, filename)\n",
    "            files_full.append(f)\n",
    "    files_full.sort(key=natural_keys)\n",
    "    j = 0\n",
    "    dict_for_inf = []\n",
    "    for filename in tqdm(files_full):\n",
    "        if not '=' in text[j] and not 'нрзб' in text[j] and not '[' in text[j] and not '<' in text[j]:\n",
    "            x = text[j].replace('\\n', '').lower()\n",
    "            x = x.replace('.', ' ')\n",
    "            x = x.replace(',', ' ')\n",
    "            x = x.replace(':', ' ')\n",
    "            x = x.replace('?', ' ')\n",
    "            x = x.replace('!', ' ')\n",
    "            x = x.replace('–', ' ')\n",
    "            x = x.replace('-', ' ')\n",
    "            x = x.replace('ё', 'е')\n",
    "            x = re.sub('(\\s){2,}', ' ', x)\n",
    "            x = re.sub('\\(.*\\)', '', x)\n",
    "            x = x.rstrip()\n",
    "            dict_for_inf.append({'respondent':inf, 'path': filename, 'sentence': x})\n",
    "        j += 1  \n",
    "    return dict_for_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5a8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 487/487 [00:00<00:00, 162293.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 234/234 [00:00<00:00, 234072.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 529/529 [00:00<00:00, 264582.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 434/434 [00:00<00:00, 216938.14it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 709/709 [00:00<00:00, 236350.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 277/277 [00:00<00:00, 277020.08it/s]\n"
     ]
    }
   ],
   "source": [
    "enm = prepare_files('/content/input_opochka/new_mono_enm20180618', \n",
    "                    '/content/input_opochka/20180618_enm1930_1to487.txt', 'ENM1930')\n",
    "ive = prepare_files('/content/input_opochka/new_mono_ive20190702', \n",
    "                    '/content/input_opochka/20190702_ive1949_1to234.txt', 'IVE1949')\n",
    "onv = prepare_files('/content/input_opochka/new_mono_onv20180622', \n",
    "                    '/content/input_opochka/20180622_onv1972_1to529.txt', 'ONV1972')\n",
    "saf = prepare_files('/content/input_opochka/new_mono_saf20190701', \n",
    "                    '/content/input_opochka/20190701_saf1973_1to434.txt', 'IVE1949')\n",
    "tai = prepare_files('/content/input_opochka/new_mono_tai20190706', \n",
    "                    '/content/input_opochka/20190706_tai1955_1to167.txt', 'TAI1955')\n",
    "tve = prepare_files('/content/input_opochka/new_mono_tve20190702', \n",
    "                    '/content/input_opochka/20190702_tve1955_1to709.txt', 'TVE1955')\n",
    "vav = prepare_files('/content/input_opochka/new_mono_vav20180619', \n",
    "                    '/content/input_opochka/20180619_vav1949_1to277.txt', 'VAV1949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a2a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256\n"
     ]
    }
   ],
   "source": [
    "all_data = enm + ive + onv + saf + tai + tve + vav\n",
    "print(len(all_data))\n",
    "train, test = train_test_split(all_data, test_size=0.3, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4418f",
   "metadata": {},
   "source": [
    "# Read audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "809f68a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 677/677 [00:33<00:00, 19.93it/s]\n"
     ]
    }
   ],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = librosa.load(batch[\"path\"], sr=16000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sentence\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "\n",
    "test_dataset = []\n",
    "\n",
    "for l in tqdm(test):\n",
    "    test_dataset.append(speech_file_to_array_fn(l))\n",
    "data = [d['speech'] for d in test_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde3a09",
   "metadata": {},
   "source": [
    "# Testing the model that was pretrained on the data of the Zapadnodvinsk villages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "995a7594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 677/677 [10:25<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "ready = []\n",
    "for d in tqdm(data):\n",
    "    inputs = processor(d, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "        ready.append([test_dataset[j][\"path\"], test_dataset[j][\"sentence\"], predicted_sentence, \n",
    "                      test_dataset[j][\"speech\"], test_dataset[j][\"respondent\"]])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4255ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 677/677 [00:00<00:00, 12086.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean WER:  0.6153097363516223\n",
      "Mean CER:  0.3702287137562663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wers = []\n",
    "cers = []\n",
    "total = []\n",
    "\n",
    "for path, correct, transcription, speech, respondent in tqdm(ready):\n",
    "    if correct != '' and correct != ' ':\n",
    "        w = wer(correct, transcription)\n",
    "        wers.append(w)\n",
    "        c = cer(correct, transcription)\n",
    "        cers.append(c)\n",
    "\n",
    "print('Mean WER: ', sum(wers)/len(wers))\n",
    "print('Mean CER: ', sum(cers)/len(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ed34aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "test_results = pd.DataFrame(ready, columns=['path', 'correct', 'transcription', 'speech', 'respondent'])\n",
    "path = \"/content/opochka_wav2vec_test.xlsx\"\n",
    "writer = pd.ExcelWriter(path, engine = 'xlsxwriter')\n",
    "\n",
    "test_results.to_excel(writer) \n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fed2f",
   "metadata": {},
   "source": [
    "# Testing the model that was not trained on dialect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "713f1373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 677/677 [10:21<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "j = 0\n",
    "ready = []\n",
    "for d in tqdm(data):\n",
    "    inputs = processor(d, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "    for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "        ready.append([test_dataset[j][\"path\"], test_dataset[j][\"sentence\"], predicted_sentence, \n",
    "                      test_dataset[j][\"speech\"], test_dataset[j][\"respondent\"]])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aa2c33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 677/677 [00:00<00:00, 10530.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean WER:  0.6594268174819736\n",
      "Mean CER:  0.40216192678043755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wers = []\n",
    "cers = []\n",
    "total = []\n",
    "\n",
    "for path, correct, transcription, speech, respondent in tqdm(ready):\n",
    "    if correct != '' and correct != ' ':\n",
    "        w = wer(correct, transcription)\n",
    "        wers.append(w)\n",
    "        c = cer(correct, transcription)\n",
    "        cers.append(c)\n",
    "\n",
    "print('Mean WER: ', sum(wers)/len(wers))\n",
    "print('Mean CER: ', sum(cers)/len(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31d1be4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "test_results = pd.DataFrame(ready, columns=['path', 'correct', 'transcription', 'speech', 'respondent'])\n",
    "path = \"/content/opochka_wav2vec_baseline.xlsx\"\n",
    "writer = pd.ExcelWriter(path, engine = 'xlsxwriter')\n",
    "\n",
    "test_results.to_excel(writer) \n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec8c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
