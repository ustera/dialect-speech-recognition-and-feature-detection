{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ea698d",
   "metadata": {},
   "source": [
    "# Import all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install datasets\n",
    "!pip install pyaspeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be412c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from pyaspeller import YandexSpeller\n",
    "from tqdm import tqdm\n",
    "from jiwer import wer, cer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f3c64",
   "metadata": {},
   "source": [
    "# Processing source files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820216c",
   "metadata": {},
   "source": [
    "Get all files, define new sort function to sort as \\[1, 2, 3 ... 100\\], because built-in function sorts strings as \\[1, 100, 101 ...\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012d648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split(r'(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929dbb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_files(directory, file_with_text, inf):\n",
    "    with open(file_with_text, encoding='utf-16') as f:\n",
    "        text = f.readlines()\n",
    "    files = os.listdir(directory)\n",
    "    files_full = []\n",
    "    for filename in files:\n",
    "        if '.DS_Store' not in filename:\n",
    "            f = os.path.join(directory, filename)\n",
    "            files_full.append(f)\n",
    "    files_full.sort(key=natural_keys)\n",
    "    j = 0\n",
    "    dict_for_inf = []\n",
    "    for filename in tqdm(files_full):\n",
    "        if not '=' in text[j] and not 'нрзб' in text[j] and not '[' in text[j] and not '<' in text[j]:\n",
    "            x = text[j].replace('\\n', '').lower()\n",
    "            x = x.replace('.', ' ')\n",
    "            x = x.replace(',', ' ')\n",
    "            x = x.replace(':', ' ')\n",
    "            x = x.replace('?', ' ')\n",
    "            x = x.replace('!', ' ')\n",
    "            x = x.replace('–', ' ')\n",
    "            x = x.replace('-', ' ')\n",
    "            x = x.replace('ё', 'е')\n",
    "            x = re.sub('(\\s){2,}', ' ', x)\n",
    "            x = re.sub('\\(.*\\)', '', x)\n",
    "            dict_for_inf.append({'respondent':inf, 'path': filename, 'sentence': x})\n",
    "        j += 1  \n",
    "    return dict_for_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74572f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 831/831 [00:00<00:00, 207703.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1159/1159 [00:00<00:00, 289701.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 856/856 [00:00<00:00, 285331.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 304/304 [00:00<00:00, 303804.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 1607/1607 [00:00<00:00, 229533.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 332/332 [00:00<00:00, 332103.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 873/873 [00:00<00:00, 291856.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 674/674 [00:00<00:00, 337064.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 659/659 [00:00<00:00, 329563.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 557/557 [00:00<00:00, 185621.11it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 677/677 [00:00<00:00, 225629.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 379/379 [00:00<00:00, 189468.56it/s]\n"
     ]
    }
   ],
   "source": [
    "lnt = prepare_files('/content/input/new_mono_lnt20210706', \n",
    "                    '/content/input/20210706_lnt1950_1to831.txt', 'LNT1950')\n",
    "mga_1307 = prepare_files('/content/input/new_mono_mga20210713', \n",
    "                         '/content/input/20210713mga1932_1to1159.txt', 'MGA1932')\n",
    "mga_1607 = prepare_files('/content/input/new_mono_mga20210716', \n",
    "                         '/content/input/20210716mga1932_1to856.txt', 'MGA1932')\n",
    "\n",
    "mga_1007 = prepare_files('/content/input/new_mono_mga20220710', \n",
    "                         '/content/input/20220710mga1932_1to304.txt', 'MGA1932')\n",
    "gip_0707 = prepare_files('/content/input/new_mono_gip20210707', \n",
    "                         '/content/input/20210707gip1953_1to1607.txt', 'GIP1953')\n",
    "gip_1507 = prepare_files('/content/input/new_mono_gip20220715', \n",
    "                         '/content/input/20220715gip1953_1to332.txt', 'GIP1953')\n",
    "gip_2704 = prepare_files('/content/input/new_mono_gip20230427', \n",
    "                         '/content/input/20230427gip1953_1to873.txt', 'GIP1953')\n",
    "\n",
    "apb_0707 = prepare_files('/content/input/new_mono_apb20220707', \n",
    "                         '/content/input/20220707apb1940_1to674.txt', 'AB1940')\n",
    "apb_1007 = prepare_files('/content/input/new_mono_apb20220710', \n",
    "                         '/content/input/20220710apb1940EZ_1to659.txt', 'AB1940')\n",
    "apb_2704 = prepare_files('/content/input/new_mono_apb20230427', \n",
    "                         '/content/input/20230427apb1940_1to557.txt', 'AB1940')\n",
    "zns_1007 = prepare_files('/content/input/new_mono_zns20220710', \n",
    "                         '/content/input/20220710zns1939_1to677.txt', 'ZNS1939')\n",
    "zns_1107 = prepare_files('/content/input/new_mono_zns20220711', \n",
    "                         '/content/input/20220711zns1939_1to379.txt', 'ZNS1939')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb621bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_records = lnt + mga_1307 + mga_1607 + mga_1007 + gip_0707 + gip_1507 + gip_2704 + apb_0707 + apb_1007 + apb_2704 + zns_1007 + zns_1107\n",
    "len(all_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e1af0",
   "metadata": {},
   "source": [
    "# Define the model and read audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df781f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_ID = \"ru\"\n",
    "MODEL_ID = \"bond005/wav2vec2-large-ru-golos-with-lm\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID, padding=True)\n",
    "model = Wav2Vec2ForCTC.from_pretrained('/content/wav2vec2-large-ru-golos-with-lm-opochka/checkpoint-2574/', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53831280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7922/7922 [05:48<00:00, 22.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = librosa.load(batch[\"path\"], sr=16000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sentence\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "\n",
    "test_dataset = []\n",
    "for l in tqdm(all_records):\n",
    "    test_dataset.append(speech_file_to_array_fn(l))\n",
    "data = [d['speech'] for d in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0349e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_dataset, columns=['respondent', 'path', 'sentence', 'speech'])\n",
    "ds = Dataset.from_pandas(df[['sentence', 'speech']])\n",
    "ds = ds.train_test_split(test_size=0.3, seed=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afaa789",
   "metadata": {},
   "source": [
    "# Prepare dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ac6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch, processor):\n",
    "    audio = batch[\"speech\"]\n",
    "    batch[\"input_values\"] = processor(audio, sampling_rate=16000).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f679eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5545 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(lambda examples: prepare_dataset(examples, processor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd9162",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8727dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def map_to_result(batch):\n",
    "    with torch.no_grad():\n",
    "        input_values = torch.tensor(batch[\"input_values\"]).unsqueeze(0)\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n",
    "    batch[\"text\"] = processor.decode(batch[\"labels\"], group_tokens=False)\n",
    "\n",
    "    return batch\n",
    "\n",
    "results = ds[\"test\"].map(map_to_result, remove_columns=ds[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150aabfb",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b6c778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean WER:  0.5828604111874978\n",
      "Mean CER:  0.3063438050043265\n"
     ]
    }
   ],
   "source": [
    "wers = []\n",
    "cers = []\n",
    "\n",
    "\n",
    "for item in results:\n",
    "    if item['text'] != '' and item['text'] != ' ':\n",
    "        w = wer(item['text'], item['pred_str'])\n",
    "        wers.append(w)\n",
    "        c = cer(item['text'], item['pred_str'])\n",
    "        cers.append(c)\n",
    "\n",
    "print('Mean WER: ', sum(wers)/len(wers))\n",
    "print('Mean CER: ', sum(cers)/len(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07fb5ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "test_results = results.to_pandas()\n",
    "path = \"/content/wav2vec_opochka_on_shetnevo_without_spellcheck.xlsx\"\n",
    "writer = pd.ExcelWriter(path, engine = 'xlsxwriter')\n",
    "\n",
    "test_results.to_excel(writer) \n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb461c97",
   "metadata": {},
   "source": [
    "# Use a spellchecker for the received transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52087e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2377/2377 [05:58<00:00,  6.64it/s]\n"
     ]
    }
   ],
   "source": [
    "speller = YandexSpeller()\n",
    "transcrtiptions_spelled = []\n",
    "for t in tqdm(results['pred_str']):\n",
    "    transcrtiptions_spelled.append(speller.spelled(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9993c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean WER:  0.5378986179137468\n",
      "Mean CER:  0.30670844485045673\n"
     ]
    }
   ],
   "source": [
    "wers = []\n",
    "cers = []\n",
    "\n",
    "for i, transcrtiption_spelled in enumerate(transcrtiptions_spelled):\n",
    "    if results['text'][i] != '' and results['text'][i] != ' ':\n",
    "        w = wer(results['text'][i], transcrtiption_spelled)\n",
    "        wers.append(w)\n",
    "        c = cer(results['text'][i], transcrtiption_spelled)\n",
    "        cers.append(c)\n",
    "        results['pred_str'][i] = transcrtiption_spelled\n",
    "\n",
    "print('Mean WER: ', sum(wers)/len(wers))\n",
    "print('Mean CER: ', sum(cers)/len(cers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eee5d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katya\\anaconda3\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "test_results = results.to_pandas()\n",
    "path = \"/content/wav2vec_opochka_on_shetnevo_with_spellcheck.xlsx\"\n",
    "writer = pd.ExcelWriter(path, engine = 'xlsxwriter')\n",
    "\n",
    "test_results.to_excel(writer) \n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7fa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
